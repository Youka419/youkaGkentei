<div class="section quiz-section">
    <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px; flex-wrap: wrap; gap: 10px;">
        <h2 style="margin: 0;">📝 問題演習（強化版：全30問）</h2>
        <div style="display: flex; gap: 10px;">
            <a href="history.html" class="wrong-questions-link" style="background: #f44336; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; font-size: 0.9em;">❌ 間違えた問題を見る</a>
            <button onclick="resetAnswers()" style="background: #ff9800; color: white; padding: 10px 20px; border-radius: 8px; border: none; cursor: pointer; font-size: 0.9em;">🔄 回答をリセット</button>
        </div>
    </div>

    <div class="question" id="question-0">
        <div class="question-text">Q1. 日本政府の「人間中心のAI社会原則」における3つの基本理念に含まれないものは？</div>
        <ul class="options">
            <li data-option="A">A）人間の尊厳</li>
            <li data-option="B">B）多様性と包摂</li>
            <li data-option="C">C）持続可能性</li>
            <li data-option="D">D）利益の最大化</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'D')">答えを確認</button>
        <div class="result correct"><strong>正解：D）</strong><br>AIは人間の幸せのためにあるべきで、単なる効率や利益追求が目的であってはならないという原則です。</div>
    </div>

    <div class="question" id="question-1">
        <div class="question-text">Q2. 「ELSI」とは何の略か？</div>
        <ul class="options">
            <li data-option="A">A）Ethical, Legal and Social Issues（倫理的・法的・社会的課題）</li>
            <li data-option="B">B）Energy, Life, Science, Intelligence</li>
            <li data-option="C">C）Economic, Labor, Security, Internet</li>
            <li data-option="D">D）Electronic, Logic, System, Interface</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>新しい科学技術（AIやゲノムなど）を社会実装する際に、技術面だけでなく、倫理・法・社会の観点から総合的に考える必要があります。</div>
    </div>

    <div class="question" id="question-2">
        <div class="question-text">Q3. 「アルゴリズム・バイアス」の例として適切なのは？</div>
        <ul class="options">
            <li data-option="A">A）過去の採用データを学習したAIが、女性や特定の人種の採用スコアを不当に低く評価してしまう。</li>
            <li data-option="B">B）計算速度が遅いこと。</li>
            <li data-option="C">C）アルゴリズムが複雑すぎること。</li>
            <li data-option="D">D）メモリ不足でエラーが出ること。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>学習データに含まれる人間の偏見（バイアス）をAIが増幅してしまう問題です。公平性（Fairness）の担保が重要です。</div>
    </div>

    <div class="question" id="question-3">
        <div class="question-text">Q4. 「フィルターバブル」とは？</div>
        <ul class="options">
            <li data-option="A">A）検索エンジンやSNSが、ユーザーの好みに合う情報ばかりを表示した結果、異なる意見や情報から隔離され、視野が狭くなる現象。</li>
            <li data-option="B">B）スパムメールをフィルタリングする機能。</li>
            <li data-option="C">C）画像のノイズを除去すること。</li>
            <li data-option="D">D）泡のように消えるメッセージ機能。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>「エコチェンバー（反響室）現象」とも関連し、社会の分断や極端な思想の先鋭化を招くリスクがあります。</div>
    </div>

    <div class="question" id="question-4">
        <div class="question-text">Q5. 「ディープフェイク」の悪用事例として問題になっているのは？</div>
        <ul class="options">
            <li data-option="A">A）著名人のポルノ動画合成や、政治家の偽発言動画による世論操作。</li>
            <li data-option="B">B）映画のCG作成。</li>
            <li data-option="C">C）昔の白黒写真をカラーにすること。</li>
            <li data-option="D">D）アバターを使ったVTuber活動。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>真偽の判定が難しく、個人の尊厳を傷つけたり、民主主義を揺るがしたりする深刻な脅威となっています。</div>
    </div>

    <div class="question" id="question-5">
        <div class="question-text">Q6. AIに対する「敵対的攻撃（Adversarial Attack）」の例は？</div>
        <ul class="options">
            <li data-option="A">A）パンダの画像に、人間には見えない微細なノイズを加えることで、AIに「テナガザル」と誤認識させる。</li>
            <li data-option="B">B）AIサーバーをハンマーで破壊する。</li>
            <li data-option="C">C）AIの電源を抜く。</li>
            <li data-option="D">D）AI開発者に嫌がらせをする。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>「Adversarial Examples（敵対的サンプル）」と呼ばれる攻撃です。自動運転車の標識認識を誤らせるリスクなどがあります。</div>
    </div>

    <div class="question" id="question-6">
        <div class="question-text">Q7. 「説明可能なAI（XAI）」が必要な理由は？</div>
        <ul class="options">
            <li data-option="A">A）AIの判断（融資拒否や医療診断など）に対して、人間が納得し、信頼するため（アカウンタビリティ）。</li>
            <li data-option="B">B）AIの計算速度を上げるため。</li>
            <li data-option="C">C）AIを喋らせるため。</li>
            <li data-option="D">D）法律で義務付けられているから（必ずしもそうではない）。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>ディープラーニングは「ブラックボックス」になりがちですが、重要事項の決定には「なぜそうなったか」の説明責任が求められます。</div>
    </div>

    <div class="question" id="question-7">
        <div class="question-text">Q8. プライバシー保護技術「k-匿名化」の弱点は？</div>
        <ul class="options">
            <li data-option="A">A）データの多様性が失われたり、背景知識を持つ攻撃者に対しては特定されるリスクがある（例：病気が1種類しかなければ特定できる）。</li>
            <li data-option="B">B）計算できない。</li>
            <li data-option="C">C）データが増えてしまう。</li>
            <li data-option="D">D）完全に安全である。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>これを克服するために、「l-多様性」や「t-近接性」といったより高度な概念が提案されています。</div>
    </div>

    <div class="question" id="question-8">
        <div class="question-text">Q9. 「差分プライバシー（Differential Privacy）」とは？</div>
        <ul class="options">
            <li data-option="A">A）データセットに特定の個人のデータが含まれていてもいなくても、出力結果（統計量など）がほぼ変わらないようにノイズを加える、数学的に厳密なプライバシー定義。</li>
            <li data-option="B">B）差分バックアップをとること。</li>
            <li data-option="C">C）個人情報を削除すること。</li>
            <li data-option="D">D）秘密鍵暗号のこと。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>AppleやGoogleも採用している、現在最も信頼性の高いプライバシー保護の基準です。精度とのトレードオフがあります。</div>
    </div>

    <div class="question" id="question-9">
        <div class="question-text">Q10. 自動運転の「トロッコ問題」が示唆する倫理的課題は？</div>
        <ul class="options">
            <li data-option="A">A）避けられない事故の際、AIは「歩行者を守る」べきか「乗員を守る」べきか、といった正解のない命の選択をどうプログラムすべきか。</li>
            <li data-option="B">B）トロッコの速度計算の問題。</li>
            <li data-option="C">C）線路の切り替え技術の問題。</li>
            <li data-option="D">D）法律で答えが決まっている。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>功利主義（多数を救う）か義務論（誰も殺してはいけない）か、倫理学的な難問をAI実装時にどう扱うかという議論です。</div>
    </div>

    <div class="question" id="question-10">
        <div class="question-text">Q11. 「ケンブリッジ・アナリティカ事件」は何の問題か？</div>
        <ul class="options">
            <li data-option="A">A）Facebookの個人データを不正利用し、心理プロファイリングを行って選挙（米国大統領選やBrexit）の投票行動を操作しようとした問題。</li>
            <li data-option="B">B）大学入試の不正問題。</li>
            <li data-option="C">C）AIによる株価操作。</li>
            <li data-option="D">D）ハッキングによる金銭窃盗。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>「マイクロターゲティング」による世論操作が、民主主義の根幹を揺るがすとして世界中で大問題になりました。</div>
    </div>

    <div class="question" id="question-11">
        <div class="question-text">Q12. 「AIアライメント（AI Alignment）」とは？</div>
        <ul class="options">
            <li data-option="A">A）AIの目標や価値観を、人間の意図や価値観と整合させる（ズレをなくす）こと。</li>
            <li data-option="B">B）AIのコードを整列させること。</li>
            <li data-option="C">C）複数のAIを連携させること。</li>
            <li data-option="D">D）AIを安く作ること。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>「ペーパークリップ最大化」の思考実験のように、AIが目的遂行のために人間にとって有害な手段をとらないように制御する重要課題です。</div>
    </div>

    <div class="question" id="question-12">
        <div class="question-text">Q13. 「ポイズニング攻撃（Data Poisoning）」とは？</div>
        <ul class="options">
            <li data-option="A">A）学習データに「毒（誤ったデータ）」を混入させ、完成したモデルの挙動を操ったり精度を下げたりする攻撃。</li>
            <li data-option="B">B）コンピュータウイルスを送ること。</li>
            <li data-option="C">C）AIに悪口を言うこと。</li>
            <li data-option="D">D）推論時にノイズを入れること。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>マイクロソフトのチャットボット「Tay」が、ユーザーから差別的発言を教え込まれて差別発言をするようになった事例が有名です。</div>
    </div>

    <div class="question" id="question-13">
        <div class="question-text">Q14. 「モデル・インバージョン攻撃」とは？</div>
        <ul class="options">
            <li data-option="A">A）公開されているAIモデルの出力結果などから、学習に使われた個人の顔写真や機微なデータを復元（逆推論）してしまう攻撃。</li>
            <li data-option="B">B）モデルを反転させること。</li>
            <li data-option="C">C）モデルをコピーすること。</li>
            <li data-option="D">D）モデルを削除すること。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>プライバシー侵害の一種です。学習済みモデルだからといってデータが含まれていないとは限らない（記憶してしまっている）ことを悪用します。</div>
    </div>

    <div class="question" id="question-14">
        <div class="question-text">Q15. 「FLI（Future of Life Institute）」が提唱した「アシロマAI原則」に含まれるものは？</div>
        <ul class="options">
            <li data-option="A">A）軍拡競争の回避、価値の整合性、再帰的自己改善の厳格な管理など。</li>
            <li data-option="B">B）AIによる完全な支配。</li>
            <li data-option="C">C）AI開発の禁止。</li>
            <li data-option="D">D）利益の独占。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>イーロン・マスクらも署名した、長期的なAIの安全性に関する世界的な原則です。</div>
    </div>

    <div class="question" id="question-15">
        <div class="question-text">Q16. 「AIガバナンス」において企業がやるべきことは？</div>
        <ul class="options">
            <li data-option="A">A）AI利用に関する社内ポリシーの策定、責任体制の明確化、リスク評価、ステークホルダーへの説明など。</li>
            <li data-option="B">B）とにかくAIを導入すること。</li>
            <li data-option="C">C）開発を全て外注すること。</li>
            <li data-option="D">D）事故が起きたら隠すこと。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>技術的な対策だけでなく、組織としての管理体制（ガバナンス）を構築することが、社会的信頼を得るために不可欠です。</div>
    </div>

    <div class="question" id="question-16">
        <div class="question-text">Q17. 「透明性（Transparency）」と「説明可能性（Explainability）」の違いは？</div>
        <ul class="options">
            <li data-option="A">A）透明性は開発プロセスやデータなどの情報の開示性、説明可能性は個別の判断理由を示せること。</li>
            <li data-option="B">B）同じ意味である。</li>
            <li data-option="C">C）透明性はガラス張りであること。</li>
            <li data-option="D">D）説明可能性はマニュアルがあること。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>「どのようなデータを使ったか（透明性）」と「なぜこの人を不合格にしたか（説明可能性）」は、どちらも信頼性（Trustworthy AI）に重要です。</div>
    </div>

    <div class="question" id="question-17">
        <div class="question-text">Q18. 「秘密計算（Secure Computation）」とは？</div>
        <ul class="options">
            <li data-option="A">A）データを暗号化したまま、復号せずに計算や分析を行う技術。</li>
            <li data-option="B">B）秘密の場所で計算すること。</li>
            <li data-option="C">C）計算結果を秘密にすること。</li>
            <li data-option="D">D）パスワードを計算すること。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>データの中身を誰にも見せずに統計処理などができるため、医療データや金融データの連携で期待されています。</div>
    </div>

    <div class="question" id="question-18">
        <div class="question-text">Q19. 「シンギュラリティ（技術的特異点）」とは？</div>
        <ul class="options">
            <li data-option="A">A）AIが自らより賢いAIを作り出せるようになり、技術進歩のスピードが無限大になり、人間の予測を超越する時点。レイ・カーツワイルが提唱。</li>
            <li data-option="B">B）AIが人間を滅ぼす日。</li>
            <li data-option="C">C）AIの計算速度が限界に達する日。</li>
            <li data-option="D">D）2045年に必ず起きる現象。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>「2045年問題」とも呼ばれますが、本当に来るのか、いつ来るのかについては専門家の間でも意見が分かれています。</div>
    </div>

    <div class="question" id="question-19">
        <div class="question-text">Q20. 「汎用人工知能（AGI）」と「特化型人工知能（Narrow AI）」の違いは？</div>
        <ul class="options">
            <li data-option="A">A）AGIは人間のようにあらゆるタスクをこなせるAI、特化型は囲碁や画像認識など特定のタスクしかできないAI。</li>
            <li data-option="B">B）AGIは強い、特化型は弱い。</li>
            <li data-option="C">C）AGIはロボット、特化型はソフト。</li>
            <li data-option="D">D）現在普及しているのはAGIである。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>現在のAI（Deep Learning含む）はほぼ全て「特化型」です。AGIの実現はAI研究の最終目標の一つです。</div>
    </div>

    <div class="question" id="question-20">
        <div class="question-text">Q21. 採用AIにおける「公平性」を担保するための手法として不適切なのは？</div>
        <ul class="options">
            <li data-option="A">A）性別や人種のカラム（列）を削除すれば、バイアスは完全に消える。</li>
            <li data-option="B">B）公平性を考慮した正則化を行う。</li>
            <li data-option="C">C）学習データの偏りを修正する。</li>
            <li data-option="D">D）結果の統計的なパリティ（均等性）を確認する。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>「住所」や「出身校」などの他の変数が性別の代理変数（Proxy）となって差別が残ることがあるため、単純な削除では不十分です。</div>
    </div>

    <div class="question" id="question-21">
        <div class="question-text">Q22. 「AIの民主化」とは？</div>
        <ul class="options">
            <li data-option="A">A）専門家でなくても、誰でも簡単にAIツールやクラウドサービスを使ってAIを開発・利用できるようになること。</li>
            <li data-option="B">B）AIが選挙権を持つこと。</li>
            <li data-option="C">C）AIが多数決で決まること。</li>
            <li data-option="D">D）AIを無料にすること。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>AutoMLやNoCodeツールの普及により、全ての人がAIの恩恵を受けられるようになるトレンドを指します。</div>
    </div>

    <div class="question" id="question-22">
        <div class="question-text">Q23. 自動運転レベル4において、事故時の責任主体は原則どうなるか？</div>
        <ul class="options">
            <li data-option="A">A）システム（運行供用者やメーカー）</li>
            <li data-option="B">B）運転者（乗員）</li>
            <li data-option="C">C）歩行者</li>
            <li data-option="D">D）警察</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>レベル4（特定条件下での完全自動運転）では、人間の運転義務がないため、原則としてシステム側の責任となります。</div>
    </div>

    <div class="question" id="question-23">
        <div class="question-text">Q24. EUの「AI法（AI Act）」における「リスクベースアプローチ」とは？</div>
        <ul class="options">
            <li data-option="A">A）AIをリスクレベル（禁止、高リスク、限定的リスク、最小リスク）に分類し、レベルに応じた規制をかける。</li>
            <li data-option="B">B）すべてのAIを禁止する。</li>
            <li data-option="C">C）すべてのAIを自由にさせる。</li>
            <li data-option="D">D）リスクが高いほど税金を安くする。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>「ソーシャルスコアリング」や「リアルタイム生体認証」などは「禁止（許容できないリスク）」とされるなど、メリハリのある規制です。</div>
    </div>

    <div class="question" id="question-24">
        <div class="question-text">Q25. 「チャットボット」などが人間と誤認されないようにするための倫理的配慮は？</div>
        <ul class="options">
            <li data-option="A">A）自分がAI（ボット）であることを明示する。</li>
            <li data-option="B">B）人間らしく振る舞い続ける。</li>
            <li data-option="C">C）嘘をつく。</li>
            <li data-option="D">D）返信を遅らせる。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>人間だと思い込ませて対話することは、ユーザーを欺く行為（ダークパターン）となり、信頼を損ないます。</div>
    </div>

    <div class="question" id="question-25">
        <div class="question-text">Q26. 「フェイクニュース」の拡散にAIがどう関与しているか？</div>
        <ul class="options">
            <li data-option="A">A）生成AIによる偽記事の量産や、SNSのレコメンドAIによる拡散の増幅（拡散力のブースト）。</li>
            <li data-option="B">B）AIは正しいニュースしか選ばない。</li>
            <li data-option="C">C）AIはニュースを読めない。</li>
            <li data-option="D">D）AIがファクトチェックを完璧に行っている。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>人間は「怒り」や「驚き」などの感情を揺さぶる情報（たとえ偽でも）を拡散しやすい傾向があり、AIがそれを増幅させてしまいます。</div>
    </div>

    <div class="question" id="question-26">
        <div class="question-text">Q27. 「デジタルクローン」の問題点は？</div>
        <ul class="options">
            <li data-option="A">A）故人のデジタルクローンを作成する場合の尊厳の冒涜や、生身の人間の代替として使われることへの倫理的懸念。</li>
            <li data-option="B">B）データ容量が大きい。</li>
            <li data-option="C">C）本物より賢くなる。</li>
            <li data-option="D">D）電気代がかかる。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>「美空ひばりAI」のように、故人を復活させることには「本人が望んでいるか不明」などの賛否両論があります。</div>
    </div>

    <div class="question" id="question-27">
        <div class="question-text">Q28. 「軍事利用（LAWS：自律型致死兵器システム）」に関する議論は？</div>
        <ul class="options">
            <li data-option="A">A）人間の介入なしに攻撃判断を行うAI兵器は禁止すべきという議論と、抑止力として必要という議論がある。</li>
            <li data-option="B">B）全面的に推奨されている。</li>
            <li data-option="C">C）技術的に不可能である。</li>
            <li data-option="D">D）国連で既に完全に合法化されている。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>「キラーロボット」とも呼ばれ、責任の所在や人道的な観点から、国際的な規制の議論が続いています。</div>
    </div>

    <div class="question" id="question-28">
        <div class="question-text">Q29. 「ソーシャル・スコアリング（信用スコア）」のリスクは？</div>
        <ul class="options">
            <li data-option="A">A）個人の行動をAIが監視・評価することで、差別やプライバシー侵害、萎縮効果（監視社会化）を生むリスク。</li>
            <li data-option="B">B）スコアが高いと得をする。</li>
            <li data-option="C">C）計算が面倒。</li>
            <li data-option="D">D）特にない。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>中国の芝麻信用などが有名ですが、公的な権利制限などに使われることには強い懸念があります（EU AI法では禁止）。</div>
    </div>

    <div class="question" id="question-29">
        <div class="question-text">Q30. 「AI倫理」を守るためにエンジニア個人ができることは？</div>
        <ul class="options">
            <li data-option="A">A）自分の作るシステムが社会に与える影響を想像し、偏ったデータを使っていないか、悪用されないか等を常に問い続ける姿勢。</li>
            <li data-option="B">B）言われた通りのものを作ることだけを考える。</li>
            <li data-option="C">C）法律さえ守れば何でも良いと考える。</li>
            <li data-option="D">D）倫理は専門家に任せる。</li>
        </ul>
        <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
        <div class="result correct"><strong>正解：A）</strong><br>最終的にコードを書くのはエンジニアです。一人ひとりの倫理観が、安全で信頼できるAI社会を作ります。</div>
    </div>
</div>