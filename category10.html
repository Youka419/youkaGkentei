<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>⑩ AI倫理・AIガバナンス - G検定 学習アプリ</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <a href="index.html" class="back-link">← トップページに戻る</a>
        
        <h1>⑩ AI倫理・AIガバナンス</h1>
        
        <div class="section">
            <div class="goals">
                <h3>🎯 到達目標</h3>
                <ul>
                    <li>各ガイドラインを通じ共通で議論されている事項を理解している</li>
                    <li>プライバシー上の問題の所在とプライバシーが問題となった著名な事例を理解している</li>
                    <li>公平性の問題としてどのような問題が存在するのか理解している</li>
                    <li>安全性に関する論点の所在と代表的な事例を理解している</li>
                    <li>セキュリティ上の課題としてどのような攻撃等が存在しているのか理解している</li>
                    <li>説明可能性や透明性を確保するにあたって考慮すべき事項を理解している</li>
                    <li>AI倫理アセスメントの必要性について理解している</li>
                </ul>
            </div>
        </div>
        
        <div class="section">
            <h2>📚 重要キーワード</h2>
            <div class="keywords">
                <div class="keyword-item"><strong>AI倫理</strong>人工知能を開発利用する際に守るべき道徳的社会的ルールや考え方</div>
                <div class="keyword-item"><strong>AIガバナンス</strong>AIを安全かつ適切に運用するための管理体制やルールを整備すること</div>
                <div class="keyword-item"><strong>ハードロー</strong>政府や公的機関によって制定され、法的拘束力を持つ法律</div>
                <div class="keyword-item"><strong>ソフトロー</strong>法的拘束力のない指針やガイドライン</div>
                <div class="keyword-item"><strong>リスクベースアプローチ</strong>AIのリスクの大きさに応じて適切な規制や対策を講じる手法</div>
                <div class="keyword-item"><strong>プライバシーバイデザイン</strong>システム設計段階からプライバシー保護を考慮する考え方</div>
                <div class="keyword-item"><strong>公平性</strong>AIが異なる個人やグループに対して公正に判断することを指す</div>
                <div class="keyword-item"><strong>アルゴリズムバイアス</strong>AIが特定の集団や属性に偏った判断をし不公平な結果を生むこと</div>
                <div class="keyword-item"><strong>敵対的攻撃（アドバーサリアルアタック）</strong>AIが誤った判断をするように意図的に操作されたデータを用いた攻撃</div>
                <div class="keyword-item"><strong>データ汚染</strong>学習データの収集作成工程を狙った攻撃</div>
                <div class="keyword-item"><strong>ディープフェイク</strong>AIのディープラーニング技術を使って映像や音声を本物のように合成改変する技術</div>
                <div class="keyword-item"><strong>説明可能性（XAI）</strong>AIの判断や予測の根拠を人が理解できる形で説明できること</div>
                <div class="keyword-item"><strong>ブラックボックス</strong>AIがどのように判断や予測を行ったのか内部の処理過程が不透明で人が理解しにくい状態</div>
                <div class="keyword-item"><strong>AI倫理アセスメント</strong>AIの開発運用において倫理的なリスクや影響を事前に評価するプロセス</div>
            </div>
        </div>
        
        <div class="section quiz-section">
            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px; flex-wrap: wrap; gap: 10px;">
                <h2 style="margin: 0;">📝 問題演習（強化版：全30問）</h2>
                <div style="display: flex; gap: 10px;">
                    <a href="history.html" class="wrong-questions-link" style="background: #f44336; color: white; padding: 10px 20px; border-radius: 8px; text-decoration: none; font-size: 0.9em;">❌ 間違えた問題を見る</a>
                    <button onclick="pauseLearning()" style="background: #2196F3; color: white; padding: 10px 20px; border-radius: 8px; border: none; cursor: pointer; font-size: 0.9em;">⏸️ 一時停止</button>
                    <button onclick="resetAnswers()" style="background: #ff9800; color: white; padding: 10px 20px; border-radius: 8px; border: none; cursor: pointer; font-size: 0.9em;">🔄 リセット</button>
                </div>
            </div>

            <div class="question" id="question-0">
                <div class="question-text">Q1. 日本政府の「人間中心のAI社会原則」における3つの基本理念に含まれないものは？</div>
                <ul class="options">
                    <li data-option="A">A）人間の尊厳</li>
                    <li data-option="B">B）利益の最大化</li>
                    <li data-option="C">C）持続可能性</li>
                    <li data-option="D">D）多様性と包摂</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'B')">答えを確認</button>
                <div class="result correct"><strong>正解：B）</strong><br>AIは一部の人のためではなく、みんなのために使われるべきという考え方です。利益の最大化は含まれません。</div>
            </div>

            <div class="question" id="question-1">
                <div class="question-text">Q2. 「ELSI」とは何の略か？</div>
                <ul class="options">
                    <li data-option="A">A）Economic, Labor, Security, Internet</li>
                    <li data-option="B">B）Energy, Life, Science, Intelligence</li>
                    <li data-option="C">C）Ethical, Legal and Social Issues（倫理的・法的・社会的課題）</li>
                    <li data-option="D">D）Electronic, Logic, System, Interface</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'C')">答えを確認</button>
                <div class="result correct"><strong>正解：C）</strong><br>新技術が社会に出るときに必ず議論すべき3つの観点（倫理・法・社会）です。</div>
            </div>

            <div class="question" id="question-2">
                <div class="question-text">Q3. 「アルゴリズム・バイアス」の例として適切なのは？</div>
                <ul class="options">
                    <li data-option="A">A）計算速度が遅いこと。</li>
                    <li data-option="B">B）過去の採用データを学習したAIが、女性や特定の人種の採用スコアを不当に低く評価してしまう。</li>
                    <li data-option="C">C）アルゴリズムが複雑すぎること。</li>
                    <li data-option="D">D）メモリ不足でエラーが出ること。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'B')">答えを確認</button>
                <div class="result correct"><strong>正解：B）</strong><br>学習データに含まれる人間の偏見（バイアス）をAIが増幅してしまう問題です。公平性（Fairness）の担保が重要です。</div>
            </div>

            <div class="question" id="question-3">
                <div class="question-text">Q4. 「フィルターバブル」とは？</div>
                <ul class="options">
                    <li data-option="A">A）スパムメールをフィルタリングする機能。</li>
                    <li data-option="B">B）画像のノイズを除去すること。</li>
                    <li data-option="C">C）泡のように消えるメッセージ機能。</li>
                    <li data-option="D">D）検索エンジンやSNSが、ユーザーの好みに合う情報ばかりを表示した結果、異なる意見や情報から隔離され、視野が狭くなる現象。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'D')">答えを確認</button>
                <div class="result correct"><strong>正解：D）</strong><br>「エコチェンバー（反響室）現象」とも関連し、社会の分断や極端な思想の先鋭化を招くリスクがあります。</div>
            </div>

            <div class="question" id="question-4">
                <div class="question-text">Q5. 「ディープフェイク」の悪用事例として問題になっているのは？</div>
                <ul class="options">
                    <li data-option="A">A）映画のCG作成。</li>
                    <li data-option="B">B）著名人のポルノ動画合成や、政治家の偽発言動画による世論操作。</li>
                    <li data-option="C">C）昔の白黒写真をカラーにすること。</li>
                    <li data-option="D">D）アバターを使ったVTuber活動。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'B')">答えを確認</button>
                <div class="result correct"><strong>正解：B）</strong><br>真偽の判定が難しく、個人の尊厳を傷つけたり、民主主義を揺るがしたりする深刻な脅威となっています。</div>
            </div>

            <div class="question" id="question-5">
                <div class="question-text">Q6. AIに対する「敵対的攻撃（Adversarial Attack）」の例は？</div>
                <ul class="options">
                    <li data-option="A">A）AIサーバーをハンマーで破壊する。</li>
                    <li data-option="B">B）パンダの画像に、人間には見えない微細なノイズを加えることで、AIに「テナガザル」と誤認識させる。</li>
                    <li data-option="C">C）AIの電源を抜く。</li>
                    <li data-option="D">D）AI開発者に嫌がらせをする。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'B')">答えを確認</button>
                <div class="result correct"><strong>正解：B）</strong><br>「Adversarial Examples（敵対的サンプル）」と呼ばれる攻撃です。自動運転車の標識認識を誤らせるリスクなどがあります。</div>
            </div>

            <div class="question" id="question-6">
                <div class="question-text">Q7. 「説明可能なAI（XAI）」が必要な理由は？</div>
                <ul class="options">
                    <li data-option="A">A）AIの計算速度を上げるため。</li>
                    <li data-option="B">B）AIを喋らせるため。</li>
                    <li data-option="C">C）AIの判断（融資拒否や医療診断など）に対して、人間が納得し、信頼するため（アカウンタビリティ）。</li>
                    <li data-option="D">D）法律で義務付けられているから（必ずしもそうではない）。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'C')">答えを確認</button>
                <div class="result correct"><strong>正解：C）</strong><br>ディープラーニングは「ブラックボックス」になりがちですが、重要事項の決定には「なぜそうなったか」の説明責任が求められます。</div>
            </div>

            <div class="question" id="question-7">
                <div class="question-text">Q8. プライバシー保護技術「k-匿名化」の弱点は？</div>
                <ul class="options">
                    <li data-option="A">A）計算できない。</li>
                    <li data-option="B">B）データの多様性が失われたり、背景知識を持つ攻撃者に対しては特定されるリスクがある（例：病気が1種類しかなければ特定できる）。</li>
                    <li data-option="C">C）データが増えてしまう。</li>
                    <li data-option="D">D）完全に安全である。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'B')">答えを確認</button>
                <div class="result correct"><strong>正解：B）</strong><br>これを克服するために、「l-多様性」や「t-近接性」といったより高度な概念が提案されています。</div>
            </div>

            <div class="question" id="question-8">
                <div class="question-text">Q9. 「差分プライバシー（Differential Privacy）」とは？</div>
                <ul class="options">
                    <li data-option="A">A）差分バックアップをとること。</li>
                    <li data-option="B">B）データセットに特定の個人のデータが含まれていてもいなくても、出力結果（統計量など）がほぼ変わらないようにノイズを加える、数学的に厳密なプライバシー定義。</li>
                    <li data-option="C">C）個人情報を削除すること。</li>
                    <li data-option="D">D）秘密鍵暗号のこと。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'B')">答えを確認</button>
                <div class="result correct"><strong>正解：B）</strong><br>AppleやGoogleも採用している、現在最も信頼性の高いプライバシー保護の基準です。精度とのトレードオフがあります。</div>
            </div>

            <div class="question" id="question-9">
                <div class="question-text">Q10. 自動運転の「トロッコ問題」が示唆する倫理的課題は？</div>
                <ul class="options">
                    <li data-option="A">A）トロッコの速度計算の問題。</li>
                    <li data-option="B">B）線路の切り替え技術の問題。</li>
                    <li data-option="C">C）法律で答えが決まっている。</li>
                    <li data-option="D">D）避けられない事故の際、AIは「歩行者を守る」べきか「乗員を守る」べきか、といった正解のない命の選択をどうプログラムすべきか。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'D')">答えを確認</button>
                <div class="result correct"><strong>正解：D）</strong><br>功利主義（多数を救う）か義務論（誰も殺してはいけない）か、倫理学的な難問をAI実装時にどう扱うかという議論です。</div>
            </div>

            <div class="question" id="question-10">
                <div class="question-text">Q11. 「ケンブリッジ・アナリティカ事件」は何の問題か？</div>
                <ul class="options">
                    <li data-option="A">A）Facebookの個人データを不正利用し、心理プロファイリングを行って選挙（米国大統領選やBrexit）の投票行動を操作しようとした問題。</li>
                    <li data-option="B">B）大学入試の不正問題。</li>
                    <li data-option="C">C）AIによる株価操作。</li>
                    <li data-option="D">D）ハッキングによる金銭窃盗。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'A')">答えを確認</button>
                <div class="result correct"><strong>正解：A）</strong><br>「マイクロターゲティング」による世論操作が、民主主義の根幹を揺るがすとして世界中で大問題になりました。</div>
            </div>

            <div class="question" id="question-11">
                <div class="question-text">Q12. 「AIアライメント（AI Alignment）」とは？</div>
                <ul class="options">
                    <li data-option="A">A）AIのコードを整列させること。</li>
                    <li data-option="B">B）AIの目標や価値観を、人間の意図や価値観と整合させる（ズレをなくす）こと。</li>
                    <li data-option="C">C）複数のAIを連携させること。</li>
                    <li data-option="D">D）AIを安く作ること。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'B')">答えを確認</button>
                <div class="result correct"><strong>正解：B）</strong><br>「ペーパークリップ最大化」の思考実験のように、AIが目的遂行のために人間にとって有害な手段をとらないように制御する重要課題です。</div>
            </div>

            <div class="question" id="question-12">
                <div class="question-text">Q13. 「ポイズニング攻撃（Data Poisoning）」とは？</div>
                <ul class="options">
                    <li data-option="A">A）コンピュータウイルスを送ること。</li>
                    <li data-option="B">B）AIに悪口を言うこと。</li>
                    <li data-option="C">C）学習データに「毒（誤ったデータ）」を混入させ、完成したモデルの挙動を操ったり精度を下げたりする攻撃。</li>
                    <li data-option="D">D）推論時にノイズを入れること。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'C')">答えを確認</button>
                <div class="result correct"><strong>正解：C）</strong><br>マイクロソフトのチャットボット「Tay」が、ユーザーから差別的発言を教え込まれて差別発言をするようになった事例が有名です。</div>
            </div>

            <div class="question" id="question-13">
                <div class="question-text">Q14. 「モデル・インバージョン攻撃」とは？</div>
                <ul class="options">
                    <li data-option="A">A）モデルを反転させること。</li>
                    <li data-option="B">B）公開されているAIモデルの出力結果などから、学習に使われた個人の顔写真や機微なデータを復元（逆推論）してしまう攻撃。</li>
                    <li data-option="C">C）モデルをコピーすること。</li>
                    <li data-option="D">D）モデルを削除すること。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'B')">答えを確認</button>
                <div class="result correct"><strong>正解：B）</strong><br>プライバシー侵害の一種です。学習済みモデルだからといってデータが含まれていないとは限らない（記憶してしまっている）ことを悪用します。</div>
            </div>

            <div class="question" id="question-14">
                <div class="question-text">Q15. 「FLI（Future of Life Institute）」が提唱した「アシロマAI原則」に含まれるものは？</div>
                <ul class="options">
                    <li data-option="A">A）AIによる完全な支配。</li>
                    <li data-option="B">B）AI開発の禁止。</li>
                    <li data-option="C">C）軍拡競争の回避、価値の整合性、再帰的自己改善の厳格な管理など。</li>
                    <li data-option="D">D）利益の独占。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'C')">答えを確認</button>
                <div class="result correct"><strong>正解：C）</strong><br>イーロン・マスクらも署名した、長期的なAIの安全性に関する世界的な原則です。</div>
            </div>

            <div class="question" id="question-15">
                <div class="question-text">Q16. 「AIガバナンス」において企業がやるべきことは？</div>
                <ul class="options">
                    <li data-option="A">A）とにかくAIを導入すること。</li>
                    <li data-option="B">B）AI利用に関する社内ポリシーの策定、責任体制の明確化、リスク評価、ステークホルダーへの説明など。</li>
                    <li data-option="C">C）開発を全て外注すること。</li>
                    <li data-option="D">D）事故が起きたら隠すこと。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'B')">答えを確認</button>
                <div class="result correct"><strong>正解：B）</strong><br>技術的な対策だけでなく、組織としての管理体制（ガバナンス）を構築することが、社会的信頼を得るために不可欠です。</div>
            </div>

            <div class="question" id="question-16">
                <div class="question-text">Q17. 「透明性（Transparency）」と「説明可能性（Explainability）」の違いは？</div>
                <ul class="options">
                    <li data-option="A">A）同じ意味である。</li>
                    <li data-option="B">B）透明性は開発プロセスやデータなどの情報の開示性、説明可能性は個別の判断理由を示せること。</li>
                    <li data-option="C">C）透明性はガラス張りであること。</li>
                    <li data-option="D">D）説明可能性はマニュアルがあること。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'B')">答えを確認</button>
                <div class="result correct"><strong>正解：B）</strong><br>「どのようなデータを使ったか（透明性）」と「なぜこの人を不合格にしたか（説明可能性）」は、どちらも信頼性（Trustworthy AI）に重要です。</div>
            </div>

            <div class="question" id="question-17">
                <div class="question-text">Q18. 「秘密計算（Secure Computation）」とは？</div>
                <ul class="options">
                    <li data-option="A">A）秘密の場所で計算すること。</li>
                    <li data-option="B">B）データを暗号化したまま、復号せずに計算や分析を行う技術。</li>
                    <li data-option="C">C）計算結果を秘密にすること。</li>
                    <li data-option="D">D）パスワードを計算すること。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'B')">答えを確認</button>
                <div class="result correct"><strong>正解：B）</strong><br>データの中身を誰にも見せずに統計処理などができるため、医療データや金融データの連携で期待されています。</div>
            </div>

            <div class="question" id="question-18">
                <div class="question-text">Q19. 「シンギュラリティ（技術的特異点）」とは？</div>
                <ul class="options">
                    <li data-option="A">A）AIが人間を滅ぼす日。</li>
                    <li data-option="B">B）AIの計算速度が限界に達する日。</li>
                    <li data-option="C">C）AIが自らより賢いAIを作り出せるようになり、技術進歩のスピードが無限大になり、人間の予測を超越する時点。レイ・カーツワイルが提唱。</li>
                    <li data-option="D">D）2045年に必ず起きる現象。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'C')">答えを確認</button>
                <div class="result correct"><strong>正解：C）</strong><br>「2045年問題」とも呼ばれますが、本当に来るのか、いつ来るのかについては専門家の間でも意見が分かれています。</div>
            </div>

            <div class="question" id="question-19">
                <div class="question-text">Q20. 「汎用人工知能（AGI）」と「特化型人工知能（Narrow AI）」の違いは？</div>
                <ul class="options">
                    <li data-option="A">A）AGIは強い、特化型は弱い。</li>
                    <li data-option="B">B）AGIはロボット、特化型はソフト。</li>
                    <li data-option="C">C）現在普及しているのはAGIである。</li>
                    <li data-option="D">D）AGIは人間のようにあらゆるタスクをこなせるAI、特化型は囲碁や画像認識など特定のタスクしかできないAI。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'D')">答えを確認</button>
                <div class="result correct"><strong>正解：D）</strong><br>現在のAI（Deep Learning含む）はほぼ全て「特化型」です。AGIの実現はAI研究の最終目標の一つです。</div>
            </div>

            <div class="question" id="question-20">
                <div class="question-text">Q21. 採用AIにおける「公平性」を担保するための手法として不適切なのは？</div>
                <ul class="options">
                    <li data-option="A">A）公平性を考慮した正則化を行う。</li>
                    <li data-option="B">B）性別や人種のカラム（列）を削除すれば、バイアスは完全に消える。</li>
                    <li data-option="C">C）学習データの偏りを修正する。</li>
                    <li data-option="D">D）結果の統計的なパリティ（均等性）を確認する。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'B')">答えを確認</button>
                <div class="result correct"><strong>正解：B）</strong><br>「住所」や「出身校」などの他の変数が性別の代理変数（Proxy）となって差別が残ることがあるため、単純な削除では不十分です（不適切なものを選ぶ問題）。</div>
            </div>

            <div class="question" id="question-21">
                <div class="question-text">Q22. 「AIの民主化」とは？</div>
                <ul class="options">
                    <li data-option="A">A）AIが選挙権を持つこと。</li>
                    <li data-option="B">B）専門家でなくても、誰でも簡単にAIツールやクラウドサービスを使ってAIを開発・利用できるようになること。</li>
                    <li data-option="C">C）AIが多数決で決まること。</li>
                    <li data-option="D">D）AIを無料にすること。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'B')">答えを確認</button>
                <div class="result correct"><strong>正解：B）</strong><br>AutoMLやNoCodeツールの普及により、全ての人がAIの恩恵を受けられるようになるトレンドを指します。</div>
            </div>

            <div class="question" id="question-22">
                <div class="question-text">Q23. 自動運転レベル4において、事故時の責任主体は原則どうなるか？</div>
                <ul class="options">
                    <li data-option="A">A）運転者（乗員）</li>
                    <li data-option="B">B）システム（運行供用者やメーカー）</li>
                    <li data-option="C">C）歩行者</li>
                    <li data-option="D">D）警察</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'B')">答えを確認</button>
                <div class="result correct"><strong>正解：B）</strong><br>レベル4（特定条件下での完全自動運転）では、人間の運転義務がないため、原則としてシステム側の責任となります。</div>
            </div>

            <div class="question" id="question-23">
                <div class="question-text">Q24. EUの「AI法（AI Act）」における「リスクベースアプローチ」とは？</div>
                <ul class="options">
                    <li data-option="A">A）すべてのAIを禁止する。</li>
                    <li data-option="B">B）すべてのAIを自由にさせる。</li>
                    <li data-option="C">C）AIをリスクレベル（禁止、高リスク、限定的リスク、最小リスク）に分類し、レベルに応じた規制をかける。</li>
                    <li data-option="D">D）リスクが高いほど税金を安くする。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'C')">答えを確認</button>
                <div class="result correct"><strong>正解：C）</strong><br>「ソーシャルスコアリング」や「リアルタイム生体認証」などは「禁止（許容できないリスク）」とされるなど、メリハリのある規制です。</div>
            </div>

            <div class="question" id="question-24">
                <div class="question-text">Q25. 「チャットボット」などが人間と誤認されないようにするための倫理的配慮は？</div>
                <ul class="options">
                    <li data-option="A">A）人間らしく振る舞い続ける。</li>
                    <li data-option="B">B）嘘をつく。</li>
                    <li data-option="C">C）返信を遅らせる。</li>
                    <li data-option="D">D）自分がAI（ボット）であることを明示する。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'D')">答えを確認</button>
                <div class="result correct"><strong>正解：D）</strong><br>人間だと思い込ませて対話することは、ユーザーを欺く行為（ダークパターン）となり、信頼を損ないます。</div>
            </div>

            <div class="question" id="question-25">
                <div class="question-text">Q26. 「フェイクニュース」の拡散にAIがどう関与しているか？</div>
                <ul class="options">
                    <li data-option="A">A）AIは正しいニュースしか選ばない。</li>
                    <li data-option="B">B）生成AIによる偽記事の量産や、SNSのレコメンドAIによる拡散の増幅（拡散力のブースト）。</li>
                    <li data-option="C">C）AIはニュースを読めない。</li>
                    <li data-option="D">D）AIがファクトチェックを完璧に行っている。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'B')">答えを確認</button>
                <div class="result correct"><strong>正解：B）</strong><br>人間は「怒り」や「驚き」などの感情を揺さぶる情報（たとえ偽でも）を拡散しやすい傾向があり、AIがそれを増幅させてしまいます。</div>
            </div>

            <div class="question" id="question-26">
                <div class="question-text">Q27. 「デジタルクローン」の問題点は？</div>
                <ul class="options">
                    <li data-option="A">A）データ容量が大きい。</li>
                    <li data-option="B">B）本物より賢くなる。</li>
                    <li data-option="C">C）故人のデジタルクローンを作成する場合の尊厳の冒涜や、生身の人間の代替として使われることへの倫理的懸念。</li>
                    <li data-option="D">D）電気代がかかる。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'C')">答えを確認</button>
                <div class="result correct"><strong>正解：C）</strong><br>「美空ひばりAI」のように、故人を復活させることには「本人が望んでいるか不明」などの賛否両論があります。</div>
            </div>

            <div class="question" id="question-27">
                <div class="question-text">Q28. 「軍事利用（LAWS：自律型致死兵器システム）」に関する議論は？</div>
                <ul class="options">
                    <li data-option="A">A）全面的に推奨されている。</li>
                    <li data-option="B">B）人間の介入なしに攻撃判断を行うAI兵器は禁止すべきという議論と、抑止力として必要という議論がある。</li>
                    <li data-option="C">C）技術的に不可能である。</li>
                    <li data-option="D">D）国連で既に完全に合法化されている。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'B')">答えを確認</button>
                <div class="result correct"><strong>正解：B）</strong><br>「キラーロボット」とも呼ばれ、責任の所在や人道的な観点から、国際的な規制の議論が続いています。</div>
            </div>

            <div class="question" id="question-28">
                <div class="question-text">Q29. 「ソーシャル・スコアリング（信用スコア）」のリスクは？</div>
                <ul class="options">
                    <li data-option="A">A）スコアが高いと得をする。</li>
                    <li data-option="B">B）計算が面倒。</li>
                    <li data-option="C">C）個人の行動をAIが監視・評価することで、差別やプライバシー侵害、萎縮効果（監視社会化）を生むリスク。</li>
                    <li data-option="D">D）特にない。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'C')">答えを確認</button>
                <div class="result correct"><strong>正解：C）</strong><br>中国の芝麻信用などが有名ですが、公的な権利制限などに使われることには強い懸念があります（EU AI法では禁止）。</div>
            </div>

            <div class="question" id="question-29">
                <div class="question-text">Q30. 「AI倫理」を守るためにエンジニア個人ができることは？</div>
                <ul class="options">
                    <li data-option="A">A）言われた通りのものを作ることだけを考える。</li>
                    <li data-option="B">B）法律さえ守れば何でも良いと考える。</li>
                    <li data-option="C">C）倫理は専門家に任せる。</li>
                    <li data-option="D">D）自分の作るシステムが社会に与える影響を想像し、偏ったデータを使っていないか、悪用されないか等を常に問い続ける姿勢。</li>
                </ul>
                <button class="answer-btn" onclick="checkAnswer(this, 'D')">答えを確認</button>
                <div class="result correct"><strong>正解：D）</strong><br>最終的にコードを書くのはエンジニアです。一人ひとりの倫理観が、安全で信頼できるAI社会を作ります。</div>
            </div>
        </div>
    </div>
    
    <script src="script.js"></script>
    <script>
        // 回答リセット機能
        function resetAnswers() {
            if (confirm('この分野の回答をリセットしますか？学習履歴からも削除されます。')) {
                const currentPage = window.location.pathname.split('/').pop().replace('.html', '');
                const history = StudyHistory.getHistory();
                if (history[currentPage]) {
                    delete history[currentPage];
                    StudyHistory.saveHistory(history);
                }
                location.reload();
            }
        }

        // 学習一時停止機能
        function pauseLearning() {
            const currentPage = window.location.pathname.split('/').pop().replace('.html', '');
            const questions = document.querySelectorAll('.question');
            let currentQuestionIndex = 0;
            
            // 未回答の最初の問題を探す
            for (let i = 0; i < questions.length; i++) {
                if (!questions[i].classList.contains('answered-correct') && !questions[i].classList.contains('answered-incorrect')) {
                    currentQuestionIndex = i;
                    break;
                }
            }
            
            const scrollPosition = window.scrollY;
            StudyHistory.saveSession(currentPage, currentQuestionIndex, scrollPosition);
            alert('学習を一時停止しました。TOPページから「学習を再開」ボタンで続きから始められます。');
            window.location.href = 'index.html';
        }
        
        // ページ読み込み時に続きから再開する機能
        document.addEventListener('DOMContentLoaded', function() {
            const session = StudyHistory.getSession();
            const currentPage = window.location.pathname.split('/').pop().replace('.html', '');
            
            // セッション情報があり、かつ同じページの場合のみ復元
            if (session && session.category === currentPage) {
                // スクロール位置を復元
                if (session.scrollPosition) {
                    setTimeout(() => {
                        window.scrollTo({
                            top: session.scrollPosition,
                            behavior: 'smooth'
                        });
                    }, 100);
                }
            }
        });
    </script>
</body>
</html>